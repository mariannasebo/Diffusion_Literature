---
title: "Literature"
author: "Marianna Seb≈ë"
format: html
editor: visual
bibliography: bibliography.bib
---

## Systematic Review



```{r}
#remotes::install_github("elizagrames/litsearchr", ref="main")
library(litsearchr)
library(dplyr)
library(ggplot2)
library(ggraph)
library(igraph)
library(readr)
```


In order to conduct a bibliometric analysis on this topic first the Web of Science is used.

(AB=(policy diffusion)) OR TS=(policy diffusion) is put in the search field enabling the possibility of exact search. The 15,097 results are refined by choosing the research domain to be social sciences to 12,244. Web of Science Core collection 11,136 English 10,933. Major concepts were set to Government and Law, Population Studies, Economics, Public Health, Methods and Techniques, Sociology, Waste Management, Development, Transport and Circulation. Overall this lead to 553 results. The Mesh Qualifiers were set to Methods, Organization Administration, Economics, Statiscs Numerical Data, Trends, Legislations Jurisprudence, Standards, Analysis. 211 results were found this way. This has generated the file: wos.txt

In Scopus with policy diffusion 950 documentts. Limiting to Social Sciences, Business, Management and Accounting and Economics, Econometrics and finance 842. Limited to English papers 820

Scopus worked!

```{r}
S <- summary(object = results, k = 10, pause = FALSE)
plot(x = results, k = 10, pause = FALSE)


```

```{r}
topAU <- authorProdOverTime(M1, k = 10, graph = TRUE)

```

```{r}
naive_results <-import_results(file="scopus.bib")

keywords <- extract_terms(keywords=naive_results[, "keywords"], method="tagged", min_n=2, min_freq = 6)
title_terms<-extract_terms(text=naive_results[, "title"], method="fakerake", min_freq=4, min_n=2)
terms <- unique(c(keywords, title_terms))
docs <- paste(naive_results[, "title"], naive_results[, "abstract"])
dfm <- create_dfm(elements=docs, features=terms)
dfm[1:3, 1:4]
g <- create_network(dfm, min_studies=4)
ggraph(g, layout="stress") +
  coord_fixed() +
  expand_limits(x=c(-3, 3)) +
  geom_edge_link(aes(alpha=weight)) +
  geom_node_point(shape="circle filled", fill="white") +
  geom_node_text(aes(label=name), hjust="outward", check_overlap=TRUE) +
  guides(edge_alpha=FALSE)

strengths <- strength(g)

data.frame(term=names(strengths), strength=strengths, row.names=NULL) %>%
  mutate(rank=rank(strength, ties.method="min")) %>%
  arrange(strength) ->
  term_strengths

term_strengths

cutoff_fig <- ggplot(term_strengths, aes(x=rank, y=strength, label=term)) +
  geom_line() +
  geom_point() +
  geom_text(data=filter(term_strengths, rank>5), hjust="right", nudge_y=20, check_overlap=TRUE)

cutoff_fig
cutoff_cum <- find_cutoff(g, method="cumulative", percent=0.8)

cutoff_cum
cutoff_fig +
  geom_hline(yintercept=cutoff_cum, linetype="dashed")




```

```{r}
#remotes::install_github("massimoaria/bibliometrix")
library(bibliometrix)
biblioshiny()

```

```{r}
library(bibliometrix)
file<-"scopus.bib"
M<-convert2df(file = file, dbsource = "scopus", format= "bibtex")
results <- biblioAnalysis(M, sep = ";")
options(width=100)
S <- summary(object = results, k = 10, pause = FALSE)
plot(x = results, k = 10, pause = FALSE)
CR <- citations(M, field = "article", sep = ";")
cbind(CR$Cited[1:10])
CR <- citations(M, field = "author", sep = ";")
cbind(CR$Cited[1:10])
topAU <- authorProdOverTime(M, k = 10, graph = TRUE)

NetMatrix <- biblioNetwork(M, analysis = "co-occurrences", network = "keywords", sep = ";")

# Plot the network
net=networkPlot(NetMatrix, normalize="association", weighted=T, n = 30, Title ="Keyword Co-occurrences", type = "fruchterman", size=T,edgesize = 5,labelsize=0.7)

CS <- conceptualStructure(M,field="ID", method="CA", minDegree=4, clust=5, stemming=FALSE, labelsize=10, documents=10)



```

```{r}
# Create keyword co-occurrences network

NetMatrix <- biblioNetwork(M, analysis = "co-occurrences", network = "keywords", sep = ";")

# Plot the network
net=networkPlot(NetMatrix, normalize="association", weighted=T, n = 30, Title = "Keyword Co-occurrences", type = "fruchterman", size=T,edgesize = 5,labelsize=0.7)
```

```{r}
CS <- conceptualStructure(M,field="ID", method="CA", minDegree=4, clust=5, stemming=FALSE, labelsize=10, documents=10)

```

```{r}
# Create a historical citation network
options(width=130)
histResults<-histNetwork(M, min.citations =1, sep = ";")

```

```{r}
#Plot a historial co-citation network
net<-histPlot(histResults, n=15, size=10, labelsize=5)
```

Link: https://github.com/singh1985/bibliometix_june22/blob/main/bibliometrix_slides_ECU_15june.Rmd

```{r}
devtools::install_github("muschellij2/rscopus")


```

```{r}

```

```{r}
#using dimension
#search "public policy" AND "diffusion" AND "innovation"
#using second option to export
#now following "public policy" AND "diffusion" AND "innovation"

github_list <- c(
  "agoutsmedt/networkflow", # manipulating network
  "ParkerICI/vite" # needed for the spatialisation of the network
)
for (p in github_list) {
  if (gsub(".*/", "", p) %in% installed.packages() == FALSE) {
    devtools::install_github(p)
  }
  library(gsub(".*/", "", p), character.only = TRUE)
}

```

```{r}

devtools::install_github("ParkerICI/vite")



```

```{r}
#if severAL DOWNLOADS
#dimensions_data_1 <- read_csv(here(dimensions_path,
#                                "dimensions_dsge_data_2015-2022.csv"),
#                           skip = 1)
#dimensions_data_2 <- read_csv(here(dimensions_path,
#                                            "dimensions_dsge_data_1996-2014.csv"),
#                                       skip = 1)

#dimensions_data <- rbind(dimensions_data_1,
#                                  dimensions_data_2) %>% 
#  clean_names() # cleaning column names with janitor to transform them

dimensions_data<- read_csv(("Dimensions-Publication-2023-02-20_11-25-47.csv"), skip=1) %>% clean_names()

dimensions_data
```

```{r}
duplicated_articles <- dimensions_data %>%
  add_count(title) %>% 
  filter(n > 1) %>% 
  arrange(title, cited_references)

to_keep <- duplicated_articles %>% 
  group_by(title) %>% 
  slice_head(n = 1)

to_remove <- duplicated_articles %>% 
  filter(! publication_id %in% to_keep$publication_id)

dimensions_data <- dimensions_data %>% 
  filter(! publication_id %in% to_remove$publication_id)
```

```{r}
references_extract <- dimensions_data %>% 
  filter(! is.na(cited_references)) %>% 
  rename("citing_id" = publication_id) %>% # because the "publication_id" column is also the identifier of the reference
  select(citing_id, cited_references) %>% 
  separate_rows(cited_references, sep = ";(?=\\[)") %>%
  as_tibble

column_names <- c("authors",
                  "author_id",
                  "source",
                  "year",
                  "volume",
                  "issue",
                  "pagination",
                  "doi",
                  "publication_id",
                  "times_cited")

dimensions_direct_citation <- references_extract %>% 
  separate(col = cited_references, into = column_names, sep = "\\|")

head(dimensions_direct_citation, n = 5)

dimensions_references <- dimensions_direct_citation %>% 
  distinct(publication_id, .keep_all = TRUE) %>% 
  select(-citing_id)
```
